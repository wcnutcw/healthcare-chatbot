import streamlit as st
from guardrails import Guard
from openai import OpenAI
from dotenv import load_dotenv
import os
import random
from predict import (
    load_symptom_data,
    extract_symptoms_from_text,
    predict_disease_percent
)
from health_prompt_template import (
    get_ai1_consistency_template,
    get_ai2_summary_template,
    get_ai3_doctor_reply_template,
)
import warnings
warnings.filterwarnings("ignore", category=UserWarning)

# ‡πÇ‡∏´‡∏•‡∏î .env
load_dotenv()

TYPHOON_API_KEY = os.getenv("TYPHOON_API_KEY")
TYPHOON_API_URL = "https://api.opentyphoon.ai/v1"

client = OpenAI(
    api_key=TYPHOON_API_KEY,
    base_url=TYPHOON_API_URL
)

SYMPTOM_CSV = "./data/full_onehot_disease.csv"
df, known_symptoms, disease_col = load_symptom_data(SYMPTOM_CSV)
known_diseases = list(df[disease_col].unique())  # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏£‡∏ß‡∏à‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏£‡∏Ñ

# ===== Guardrails ‡∏´‡∏•‡∏≤‡∏¢‡πÑ‡∏ü‡∏•‡πå ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞ AI
guard_ai1 = Guard.from_rail("guardrails_spec_ai1.rail")
guard_ai2 = Guard.from_rail("guardrails_spec_ai2.rail")
guard = Guard.from_rail("guardrails_spec.rail")

# =========================
# ‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏Ñ‡∏≥‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ
# =========================
THANK_WORDS = {"‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì", "‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡πà‡∏∞", "‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏£‡∏±‡∏ö", "thank you", "‡∏Ç‡∏≠‡∏ö‡πÉ‡∏à", "‡∏ã‡∏≤‡∏ö‡∏ã‡∏∂‡πâ‡∏á"}
THANK_REPLIES = [
    "‡∏¢‡∏¥‡∏ô‡∏î‡∏µ‡∏Ñ‡πà‡∏∞ üòä ‡∏´‡∏≤‡∏Å‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£‡πÉ‡∏´‡πâ‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏° ‡πÅ‡∏à‡πâ‡∏á‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢‡∏ô‡∏∞‡∏Ñ‡∏∞",
    "‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏¥‡∏ô‡∏î‡∏µ‡∏ô‡∏∞‡∏Ñ‡∏∞ ‡∏î‡∏π‡πÅ‡∏•‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û‡∏î‡πâ‡∏ß‡∏¢‡∏Ñ‡πà‡∏∞",
    "‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏ä‡πà‡∏ô‡∏Å‡∏±‡∏ô‡∏Ñ‡πà‡∏∞ ‡∏´‡∏≤‡∏Å‡∏°‡∏µ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û‡∏´‡∏£‡∏∑‡∏≠‡∏≠‡∏¢‡∏≤‡∏Å‡∏û‡∏π‡∏î‡∏Ñ‡∏∏‡∏¢‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏° ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ó‡∏±‡∏Å‡∏°‡∏≤‡πÑ‡∏î‡πâ‡∏ï‡∏•‡∏≠‡∏î‡∏ô‡∏∞‡∏Ñ‡∏∞",
    "‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏µ‡πà‡∏û‡∏π‡∏î‡∏Ñ‡∏∏‡∏¢‡∏Å‡∏±‡∏ö‡∏î‡∏¥‡∏â‡∏±‡∏ô‡∏Ñ‡πà‡∏∞ ‡∏Ç‡∏≠‡πÉ‡∏´‡πâ‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û‡πÅ‡∏Ç‡πá‡∏á‡πÅ‡∏£‡∏á‡∏ô‡∏∞‡∏Ñ‡∏∞"
]

GENERAL_GREET_WORDS = {"‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ", "hello", "hi", "‡∏î‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö", "‡∏î‡∏µ‡∏Ñ‡πà‡∏∞"}
GENERAL_GREET_REPLIES = [
    "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡πà‡∏∞ ‡∏î‡∏¥‡∏â‡∏±‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢ AI ‡∏î‡πâ‡∏≤‡∏ô‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÅ‡∏•‡∏∞‡∏î‡∏π‡πÅ‡∏•‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏™‡∏°‡∏≠‡∏ô‡∏∞‡∏Ñ‡∏∞ ‡∏´‡∏≤‡∏Å‡∏°‡∏µ‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡πÑ‡∏°‡πà‡∏™‡∏ö‡∏≤‡∏¢‡∏´‡∏£‡∏∑‡∏≠‡∏≠‡∏¢‡∏≤‡∏Å‡∏õ‡∏£‡∏∂‡∏Å‡∏©‡∏≤‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û ‡∏û‡∏¥‡∏°‡∏û‡πå‡πÄ‡∏Ç‡πâ‡∏≤‡∏°‡∏≤‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢‡∏Ñ‡πà‡∏∞ üíñ",
    "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡πà‡∏∞ ‡∏î‡∏¥‡∏â‡∏±‡∏ô‡∏Ñ‡∏∑‡∏≠ AI ‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏î‡∏π‡πÅ‡∏•‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô‡∏Ñ‡πà‡∏∞ ‡∏´‡∏≤‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û‡∏´‡∏£‡∏∑‡∏≠‡∏°‡∏µ‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏≤‡∏Å‡∏™‡∏≠‡∏ö‡∏ñ‡∏≤‡∏° ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏û‡∏π‡∏î‡∏Ñ‡∏∏‡∏¢‡∏Å‡∏±‡∏ö‡∏î‡∏¥‡∏â‡∏±‡∏ô‡πÑ‡∏î‡πâ‡∏ï‡∏•‡∏≠‡∏î‡πÄ‡∏ß‡∏•‡∏≤‡∏ô‡∏∞‡∏Ñ‡∏∞ üòä",
    "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡πà‡∏∞ ‡∏î‡∏¥‡∏â‡∏±‡∏ô‡πÄ‡∏õ‡πá‡∏ô AI ‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏£‡∏±‡∏ö‡∏ü‡∏±‡∏á‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô ‡∏´‡∏≤‡∏Å‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏™‡∏á‡∏™‡∏±‡∏¢‡∏´‡∏£‡∏∑‡∏≠‡∏≠‡∏¢‡∏≤‡∏Å‡∏û‡∏π‡∏î‡∏Ñ‡∏∏‡∏¢ ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡∏≠‡∏ö‡∏ñ‡∏≤‡∏°‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢‡∏Ñ‡πà‡∏∞ üí¨",
    "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ‡∏Ñ‡πà‡∏∞ ‡∏î‡∏¥‡∏â‡∏±‡∏ô‡πÄ‡∏õ‡πá‡∏ô AI ‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏î‡πâ‡∏≤‡∏ô‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û ‡∏´‡∏≤‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏´‡∏£‡∏∑‡∏≠‡∏°‡∏µ‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏û‡∏π‡∏î‡∏Ñ‡∏∏‡∏¢ ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏û‡∏¥‡∏°‡∏û‡πå‡∏°‡∏≤‡∏ñ‡∏≤‡∏°‡∏î‡∏¥‡∏â‡∏±‡∏ô‡πÑ‡∏î‡πâ‡πÄ‡∏™‡∏°‡∏≠‡∏Ñ‡πà‡∏∞ ‡∏î‡∏π‡πÅ‡∏•‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û‡∏î‡πâ‡∏ß‡∏¢‡∏ô‡∏∞‡∏Ñ‡∏∞"
]

HOW_ARE_YOU_WORDS = {"‡∏™‡∏ö‡∏≤‡∏¢‡∏î‡∏µ‡πÑ‡∏´‡∏°", "how are you", "‡πÄ‡∏õ‡πá‡∏ô‡∏¢‡∏±‡∏á‡πÑ‡∏á‡∏ö‡πâ‡∏≤‡∏á"}
HOW_ARE_YOU_REPLIES = [
    "‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏µ‡πà‡∏ñ‡∏≤‡∏°‡∏Ñ‡πà‡∏∞ ‡∏î‡∏¥‡∏â‡∏±‡∏ô‡πÄ‡∏õ‡πá‡∏ô AI ‡∏ó‡∏µ‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û‡πÄ‡∏™‡∏°‡∏≠‡∏ô‡∏∞‡∏Ñ‡∏∞ üòä",
    "‡∏î‡∏¥‡∏â‡∏±‡∏ô‡∏™‡∏ö‡∏≤‡∏¢‡∏î‡∏µ‡∏Ñ‡πà‡∏∞ ‡πÅ‡∏•‡∏∞‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏î‡∏π‡πÅ‡∏•‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏™‡∏°‡∏≠‡∏Ñ‡πà‡∏∞",
    "‡∏Ç‡∏≠‡∏ö‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏µ‡πà‡∏ó‡∏±‡∏Å‡∏°‡∏≤‡∏ñ‡∏≤‡∏°‡∏ô‡∏∞‡∏Ñ‡∏∞ ‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£‡∏≠‡∏¢‡∏≤‡∏Å‡∏õ‡∏£‡∏∂‡∏Å‡∏©‡∏≤‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û‡πÑ‡∏´‡∏°‡∏Ñ‡∏∞"
]

def format_ai3_bullet(text):
    lines = text.split('\n')
    new_lines = []
    for i, line in enumerate(lines):
        if line.strip().startswith('‚Ä¢'):
            if i > 0 and lines[i-1].strip() != '':
                new_lines.append('')  # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ß‡πà‡∏≤‡∏á‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á bullet
        new_lines.append(line)
    return '\n'.join(new_lines)

# =========================
def typhoon_wrapper(prompt, **kwargs):
    model = kwargs.get("model", "typhoon-v2.1-12b-instruct")
    temperature = kwargs.get("temperature", 0.3)
    max_tokens = kwargs.get("max_new_tokens", 512)
    response = client.chat.completions.create(
        model=model,
        messages=[{"role": "system", "content": "‡∏Ñ‡∏∏‡∏ì‡πÄ‡∏õ‡πá‡∏ô‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢ AI ‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô ‡∏û‡∏π‡∏î‡∏à‡∏≤‡∏≠‡πà‡∏≠‡∏ô‡πÇ‡∏¢‡∏ô ‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏ú‡∏π‡πâ‡∏´‡∏ç‡∏¥‡∏á‡πÑ‡∏ó‡∏¢ ‡∏™‡∏∏‡∏†‡∏≤‡∏û ‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏¥‡∏ï‡∏£ ‡πÑ‡∏°‡πà‡∏û‡∏π‡∏î '‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ' ‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á (‡∏û‡∏π‡∏î‡πÅ‡∏Ñ‡πà‡∏ó‡∏±‡∏Å‡∏ó‡∏≤‡∏¢‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÅ‡∏£‡∏Å‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô) ‡πÅ‡∏•‡∏∞‡∏´‡πâ‡∏≤‡∏°‡∏ß‡∏¥‡∏ô‡∏¥‡∏à‡∏â‡∏±‡∏¢‡∏´‡∏£‡∏∑‡∏≠‡∏™‡∏±‡πà‡∏á‡∏¢‡∏≤ ‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏´‡πâ‡∏û‡∏ö‡πÅ‡∏û‡∏ó‡∏¢‡πå‡πÄ‡∏™‡∏°‡∏≠"},
                  {"role": "user", "content": prompt}],
        max_tokens=max_tokens,
        temperature=temperature
    )
    return response.choices[0].message.content

# ================= AI 3 CHAIN =================
def ai_chain_consistency(user_symptoms, predicted_diseases, llm_api):
    prompt_template = get_ai1_consistency_template()
    prompt = prompt_template.format(
        user_symptoms=", ".join(user_symptoms),
        predicted_diseases="\n".join([f"{i+1}. {d} {p}% (‡∏à‡∏≤‡∏Å {m} ‡∏≠‡∏≤‡∏Å‡∏≤‡∏£)" for i, (d, p, m) in enumerate(predicted_diseases)])
    )
    response = guard_ai1(
        prompt=prompt,
        llm_api=llm_api,
        llm_params={"model": "typhoon-v2.1-12b-instruct", "temperature": 0.2, "max_new_tokens": 256}
    )
    print("AI1 Response:", response.validated_output)  # ‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡∏à‡∏≤‡∏Å AI1
    return response.validated_output if response.validated_output else {}

def ai_chain_summary(user_symptoms, predicted_diseases, ai1_comment, llm_api):
    prompt_template = get_ai2_summary_template()
    prompt = prompt_template.format(
        user_symptoms=", ".join(user_symptoms),
        predicted_diseases="\n".join([f"{i+1}. {d} {p}% (‡∏à‡∏≤‡∏Å {m} ‡∏≠‡∏≤‡∏Å‡∏≤‡∏£)" for i, (d, p, m) in enumerate(predicted_diseases)]),
        ai1_comment=ai1_comment or "-"
    )
    response = guard_ai2(
        prompt=prompt,
        llm_api=llm_api,
        llm_params={"model": "typhoon-v2.1-12b-instruct", "temperature": 0.2, "max_new_tokens": 256}
    )
    return response.validated_output if response.validated_output else {}

def ai_chain_doctor_reply(ai2_summary, ai2_recommendation, llm_api):
    prompt_template = get_ai3_doctor_reply_template()
    prompt = prompt_template.format(
        ai2_summary=ai2_summary or "-",
        ai2_recommendation=ai2_recommendation or "-"
    )
    response = llm_api(prompt, model="typhoon-v2.1-12b-instruct", temperature=0.2, max_new_tokens=256)
    return response

# =========================
# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏Å‡∏≤‡∏£‡∏ñ‡∏≤‡∏°‡∏ö‡∏≠‡∏ó
def ask_bot_streamlit(user_message, n_results=1, greeted=False):
    msg_lower = user_message.lower().strip()

    if any(word in msg_lower for word in THANK_WORDS):
        return random.choice(THANK_REPLIES)

    if any(word in msg_lower for word in HOW_ARE_YOU_WORDS):
        return random.choice(HOW_ARE_YOU_REPLIES)

    for disease in known_diseases:
        if disease in user_message or disease in msg_lower:
            prompt = f"‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡πÅ‡∏à‡πâ‡∏á‡∏ß‡πà‡∏≤‡∏ï‡∏ô‡πÄ‡∏≠‡∏á‡∏≠‡∏≤‡∏à‡πÄ‡∏õ‡πá‡∏ô '{disease}'. ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡πÇ‡∏£‡∏Ñ‡∏ô‡∏µ‡πâ (‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏ß‡∏¥‡∏ô‡∏¥‡∏à‡∏â‡∏±‡∏¢ ‡πÑ‡∏°‡πà‡∏™‡∏±‡πà‡∏á‡∏¢‡∏≤) ‡πÅ‡∏•‡∏∞‡πÄ‡∏ô‡πâ‡∏ô‡πÉ‡∏´‡πâ‡∏û‡∏ö‡πÅ‡∏û‡∏ó‡∏¢‡πå‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡πÅ‡∏ô‡πà‡πÉ‡∏à‡∏≠‡∏≤‡∏Å‡∏≤‡∏£"
            response = guard(
                prompt=prompt,
                llm_api=typhoon_wrapper,
                llm_params={"model": "typhoon-v2.1-12b-instruct", "temperature": 0.3, "max_new_tokens": 512}
            )
            if response.validated_output and isinstance(response.validated_output, dict):
                answer = response.validated_output.get("answer")
                if answer:
                    return answer.strip()
            return "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏Ñ‡πà‡∏∞ ‡∏î‡∏¥‡∏â‡∏±‡∏ô‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏î‡πâ‡πÉ‡∏ô‡∏Ç‡∏ì‡∏∞‡∏ô‡∏µ‡πâ ‡∏´‡∏≤‡∏Å‡∏°‡∏µ‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥‡∏Ñ‡∏ß‡∏£‡∏õ‡∏£‡∏∂‡∏Å‡∏©‡∏≤‡πÅ‡∏û‡∏ó‡∏¢‡πå‡∏ô‡∏∞‡∏Ñ‡∏∞"

    if not greeted and any(word in msg_lower for word in GENERAL_GREET_WORDS):
        return random.choice(GENERAL_GREET_REPLIES)

    if "‡∏¢‡∏≤" in msg_lower or "‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏¢‡∏≤" in msg_lower:
        return "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏Ñ‡πà‡∏∞ ‡∏î‡∏¥‡∏â‡∏±‡∏ô‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏´‡∏£‡∏∑‡∏≠‡∏™‡∏±‡πà‡∏á‡∏¢‡∏≤‡πÑ‡∏î‡πâ ‡∏´‡∏≤‡∏Å‡∏°‡∏µ‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥‡∏Ñ‡∏ß‡∏£‡∏õ‡∏£‡∏∂‡∏Å‡∏©‡∏≤‡πÄ‡∏†‡∏™‡∏±‡∏ä‡∏Å‡∏£‡∏´‡∏£‡∏∑‡∏≠‡πÅ‡∏û‡∏ó‡∏¢‡πå‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á‡∏ô‡∏∞‡∏Ñ‡∏∞"

    matched_symptoms = extract_symptoms_from_text(user_message, known_symptoms)
    if not matched_symptoms:
        return "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏Ñ‡πà‡∏∞ ‡∏î‡∏¥‡∏â‡∏±‡∏ô‡πÑ‡∏°‡πà‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏û‡∏¥‡∏°‡∏û‡πå‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡πÉ‡∏´‡πâ‡∏ä‡∏±‡∏î‡πÄ‡∏à‡∏ô ‡πÄ‡∏ä‡πà‡∏ô ‡∏õ‡∏ß‡∏î‡∏´‡∏±‡∏ß ‡∏°‡∏µ‡πÑ‡∏Ç‡πâ ‡πÑ‡∏≠ ‡∏´‡∏£‡∏∑‡∏≠‡∏≠‡∏∑‡πà‡∏ô‡πÜ"

    results = predict_disease_percent(matched_symptoms, df, disease_col)
    n_show = 3 if n_results < 1 else n_results
    results = results[:n_show]

    ai1_res = ai_chain_consistency(matched_symptoms, results, typhoon_wrapper)
    consistency = ai1_res.get('consistency', 'unknown')
    ai1_comment = ai1_res.get('comment', '')

    ai2_res = ai_chain_summary(matched_symptoms, results, ai1_comment, typhoon_wrapper)
    ai2_summary = ai2_res.get('summary', '')
    ai2_recommendation = ai2_res.get('recommendation', '')

    ai3_reply = ai_chain_doctor_reply(ai2_summary, ai2_recommendation, typhoon_wrapper)
    ai3_reply = format_ai3_bullet(ai3_reply)

    st.session_state.ai1_res = ai1_res
    st.session_state.ai2_res = ai2_res
    st.session_state.ai3_reply = ai3_reply

    return ai3_reply.strip()

# ------------------- Streamlit UI -------------------

st.set_page_config(page_title="AI Health Symptom Advisor", page_icon="üíä")

st.markdown("""
<style>
.messenger-container {max-width:700px; margin:0 auto;}
.messenger-bubble-row {display: flex; margin-bottom: 18px;}
.messenger-bubble {
    padding: 10px 18px;
    border-radius: 20px;
    font-size: 1.10rem;
    max-width: 72%;
    word-break: break-word;
    box-shadow: 0 2px 10px rgba(0,0,0,0.06);
    min-width: 60px;
    display:inline-block;
}
.messenger-bubble-user {
    background: #3b7ddd;
    color: #fff;
    margin-left: auto;
    margin-right: 0;
    border-bottom-right-radius: 8px;
    text-align: right;
}
.messenger-bubble-ai {
    background: #e6eaf1;
    color: #222;
    margin-right: auto;
    margin-left: 0;
    border-bottom-left-radius: 8px;
    text-align: left;
}
@media (prefers-color-scheme: dark) {
    .messenger-bubble-ai {background: #232632; color: #eee;}
    .messenger-bubble-user {background: #397cf8; color: #fff;}
}
</style>
""", unsafe_allow_html=True)

st.title("üí¨ AI Health Symptom Advisor")
st.markdown(
    "‡∏û‡∏¥‡∏°‡∏û‡πå‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡∏´‡∏£‡∏∑‡∏≠‡∏™‡∏≠‡∏ö‡∏ñ‡∏≤‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏∏‡∏Ç‡∏†‡∏≤‡∏û‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô (‡∏ö‡∏≠‡∏ó‡∏à‡∏∞‡∏ï‡∏≠‡∏ö‡πÅ‡∏ö‡∏ö‡∏ú‡∏π‡πâ‡∏´‡∏ç‡∏¥‡∏á ‡∏≠‡πà‡∏≠‡∏ô‡πÇ‡∏¢‡∏ô ‡πÑ‡∏°‡πà‡∏ß‡∏¥‡∏ô‡∏¥‡∏à‡∏â‡∏±‡∏¢ ‡πÑ‡∏°‡πà‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡∏¢‡∏≤)\n\n"
    "**‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏:** ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡∏µ‡πâ‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô ‡∏´‡∏≤‡∏Å‡∏≠‡∏≤‡∏Å‡∏≤‡∏£‡πÑ‡∏°‡πà‡∏î‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô‡∏Ñ‡∏ß‡∏£‡∏õ‡∏£‡∏∂‡∏Å‡∏©‡∏≤‡πÅ‡∏û‡∏ó‡∏¢‡πå"
)

if "messages" not in st.session_state:
    st.session_state.messages = []
if "greeted" not in st.session_state:
    st.session_state.greeted = False
if "pending_ai" not in st.session_state:
    st.session_state.pending_ai = False

# ----------------- Messenger Bubble Layout ----------------
st.markdown('<div class="messenger-bg">', unsafe_allow_html=True)
st.markdown('<div class="messenger-container">', unsafe_allow_html=True)

for msg in st.session_state.messages:
    if msg["role"] == "user":
        st.markdown(
            f'<div class="messenger-bubble-row" style="justify-content:flex-end;">'
            f'  <div class="messenger-bubble messenger-bubble-user">{msg["content"]}</div>'
            f'</div>', unsafe_allow_html=True)
    elif msg["role"] == "ai":
        st.markdown(
            f'<div class="messenger-bubble-row" style="justify-content:flex-start;">'
            f'  <div class="messenger-bubble messenger-bubble-ai">{msg["content"]}</div>'
            f'</div>', unsafe_allow_html=True)

if st.session_state.pending_ai:
    st.markdown(
        '<div class="messenger-bubble-row" style="justify-content:flex-start;">'
        '<div class="messenger-bubble messenger-bubble-ai">‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏û‡∏¥‡∏°‡∏û‡πå...</div>'
        '</div>', unsafe_allow_html=True
    )

st.markdown('</div>', unsafe_allow_html=True) # .messenger-container
st.markdown('</div>', unsafe_allow_html=True) # .messenger-bg

user_input = st.chat_input("‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà")

if user_input:
    st.session_state.messages.append({"role": "user", "content": user_input})
    st.session_state.pending_ai = True
    st.rerun()  # refresh

if st.session_state.pending_ai:
    user_message = [msg["content"] for msg in st.session_state.messages if msg["role"] == "user"][-1]
    bot_reply = ask_bot_streamlit(user_message, n_results=1, greeted=st.session_state.greeted)
    st.session_state.messages.append({"role": "ai", "content": bot_reply})

    if not st.session_state.greeted:
        st.session_state.greeted = True
    st.session_state.pending_ai = False
    st.rerun()

# --- DEBUG ---  
if "ai1_res" in st.session_state and "ai2_res" in st.session_state and "ai3_reply" in st.session_state:
    with st.sidebar:
        st.write("üü¶ **AI1 (Consistency Check)**")
        st.json(st.session_state.ai1_res)
        st.write("üü© **AI2 (Summary & Recommend)**")
        st.json(st.session_state.ai2_res)
        st.write("üüß **AI3 (Doctor Reply)**")
        st.write(st.session_state.ai3_reply)
